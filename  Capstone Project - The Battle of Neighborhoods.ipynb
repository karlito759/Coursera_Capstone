{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Capstone Project - The Battle of Neighborhoods (FINAL PROJECT )"}, {"metadata": {}, "cell_type": "markdown", "source": "# Business Problem\n"}, {"metadata": {}, "cell_type": "markdown", "source": "For the opening of a new restaurant in Paris, we will find out what is the best location "}, {"metadata": {}, "cell_type": "markdown", "source": "## Background and Problem Statement"}, {"metadata": {}, "cell_type": "markdown", "source": "There are a lot of restaurants in Paris and the competition is stiff. To establish a new restaurant it is important to study the different districts. We want to open a Mexican restaurant, so we have to find the most suitable location to attract the most customers "}, {"metadata": {}, "cell_type": "markdown", "source": "## Objective"}, {"metadata": {}, "cell_type": "markdown", "source": "In this assignment, we want to find the good district from 20 districts to open a **Mexican Restaurant** in Paris, France.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Audience"}, {"metadata": {}, "cell_type": "markdown", "source": "Firstly, we want to reach the Mexican community in Paris in order to ensure a loyal clientele, then we also want to be in a frequented place where there is little competition for this type of restaurant."}, {"metadata": {}, "cell_type": "markdown", "source": "# Our Approach"}, {"metadata": {}, "cell_type": "markdown", "source": "Firstly, we build the Paris neighborhood data (Postcode, Neighborhood).\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Secondly, we build the coordinates of all districts in Paris, France."}, {"metadata": {}, "cell_type": "markdown", "source": "Thirdly, we need to explore, segment and using KMeans to cluster the neighborhoods in the city of Paris based on the top 10 venues for each neighborhood district.\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Finally, we analyze the clustering result and then propose some suggestion location (district) to open Vietnamese Restaurant in Paris. Then, we give some perspectives to enhance the performances"}, {"metadata": {}, "cell_type": "markdown", "source": "## Data Settings"}, {"metadata": {}, "cell_type": "markdown", "source": "To explore our problem, we need build Paris neighborhood data and their coordinates.\nConcerning to Paris neighborhood data, we use the following references:\nParis Arrondissements & Neighborhoods Map (https://parismap360.com/paris-arrondissement-map#.XfVpqtEo91l)\nArrondissements in Paris, France (https://francetravelplanner.com/go/paris/areas/arrondismt.html)\nConcerning to relative coordinates (latitude, longitude) of each district in Paris\nUsing package geopy to convert an address into latitude and longitude values"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport pandas as pd\n\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\nfrom geopy.extra.rate_limiter import RateLimiter", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "COL_NAME_POSTCODE = \"postcode\"\nCOL_NAME_COUNTRY = \"country\"\nCOL_NAME_ADDRESS = \"address\"\nCOL_NAME_LOCATION = \"location\"\nCOL_NAME_POINT = \"point\"\nCOL_NAME_LATITUDE = \"latitude\"\nCOL_NAME_LONGITUDE = \"longitude\"\nCOL_NAME_ALTITUDE = \"altitude\"\nCOL_NAME_NEIGHBOURHOOD = \"neighbourhood\"\n\nfile_coordinate_path = \"./var/Geospatial_Coordinates_Paris.csv\"\nfile_neighbourhood_path = \"./var/Paris_Neighbourhood.csv\"", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Building the Paris neighborhood data"}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating new or Loading neighbourhood data of Paris from csv"}, {"metadata": {}, "cell_type": "code", "source": "if os.path.exists(file_neighbourhood_path):\n    print(\"Loading Paris neighbourhood data from file : %s\" % file_neighbourhood_path)\n    df_neighbourhood = pd.read_csv(file_neighbourhood_path, header=0)\nelse:\n    # The following neighbourhood data of Paris that I built based on the information in\n    # https://parismap360.com/paris-arrondissement-map#.XfXp89Eo91m\n    # https://francetravelplanner.com/go/paris/areas/arrondismt.html\n    list_neighbourhood = [\n    [\"75001\", \"75002\"], [\"75001\", \"75003\"], [\"75001\", \"75004\"], [\"75001\", \"75005\"], \n    [\"75001\", \"75006\"], [\"75001\", \"75007\"], [\"75001\", \"75008\"], [\"75001\", \"75009\"], \n    [\"75002\", \"75001\"], [\"75002\", \"75003\"], [\"75002\", \"75009\"], [\"75002\", \"75010\"],\n    [\"75003\", \"75001\"], [\"75003\", \"75002\"], [\"75003\", \"75004\"], [\"75003\", \"75010\"],\n    [\"75003\", \"75011\"], [\"75004\", \"75001\"], [\"75004\", \"75003\"], [\"75004\", \"75005\"],\n    [\"75004\", \"75006\"], [\"75004\", \"75011\"], [\"75004\", \"75012\"], [\"75005\", \"75001\"],\n    [\"75005\", \"75004\"], [\"75005\", \"75006\"], [\"75005\", \"75012\"], [\"75005\", \"75013\"],\n    [\"75005\", \"75014\"], [\"75006\", \"75001\"], [\"75006\", \"75004\"], [\"75006\", \"75005\"],\n    [\"75006\", \"75007\"], [\"75006\", \"75014\"], [\"75006\", \"75015\"], [\"75007\", \"75001\"],\n    [\"75007\", \"75006\"], [\"75007\", \"75008\"], [\"75007\", \"75015\"], [\"75007\", \"75016\"],\n    [\"75008\", \"75001\"], [\"75008\", \"75007\"], [\"75008\", \"75009\"], [\"75008\", \"75016\"],\n    [\"75008\", \"75017\"], [\"75008\", \"75018\"], [\"75009\", \"75001\"], [\"75009\", \"75002\"],\n    [\"75009\", \"75008\"], [\"75009\", \"75010\"], [\"75009\", \"75017\"], [\"75009\", \"75018\"],\n    [\"75010\", \"75002\"], [\"75010\", \"75003\"], [\"75010\", \"75009\"], [\"75010\", \"75011\"],\n    [\"75010\", \"75018\"], [\"75010\", \"75019\"], [\"75010\", \"75020\"], [\"75011\", \"75003\"],\n    [\"75011\", \"75004\"], [\"75011\", \"75010\"], [\"75011\", \"75012\"], [\"75011\", \"75019\"],\n    [\"75011\", \"75020\"], [\"75012\", \"75004\"], [\"75012\", \"75005\"], [\"75012\", \"75011\"],\n    [\"75012\", \"75013\"], [\"75012\", \"75020\"], [\"75013\", \"75005\"], [\"75013\", \"75012\"],\n    [\"75013\", \"75014\"], [\"75014\", \"75005\"], [\"75014\", \"75006\"], [\"75014\", \"75013\"],\n    [\"75014\", \"75015\"], [\"75015\", \"75006\"], [\"75015\", \"75007\"], [\"75015\", \"75014\"],\n    [\"75015\", \"75016\"], [\"75016\", \"75007\"], [\"75016\", \"75008\"], [\"75016\", \"75015\"],\n    [\"75016\", \"75017\"], [\"75017\", \"75008\"], [\"75017\", \"75009\"], [\"75017\", \"75016\"],\n    [\"75017\", \"75018\"], [\"75018\", \"75008\"], [\"75018\", \"75009\"], [\"75018\", \"75010\"],\n    [\"75018\", \"75017\"], [\"75018\", \"75019\"], [\"75019\", \"75010\"], [\"75019\", \"75011\"],\n    [\"75019\", \"75018\"], [\"75019\", \"75020\"], [\"75020\", \"75010\"], [\"75020\", \"75011\"],\n    [\"75020\", \"75012\"], [\"75020\", \"75019\"]]\n\n    df_neighbourhood = pd.DataFrame(data=list_neighbourhood, columns=[COL_NAME_POSTCODE, COL_NAME_NEIGHBOURHOOD])\n\n    df_neighbourhood.to_csv(file_neighbourhood_path, header=True, index=False)", "execution_count": 12, "outputs": [{"output_type": "error", "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: 'var/Paris_Neighbourhood.csv'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-12-593ccf76dd96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdf_neighbourhood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_neighbourhood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOL_NAME_POSTCODE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOL_NAME_NEIGHBOURHOOD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf_neighbourhood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_neighbourhood_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'var/Paris_Neighbourhood.csv'"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Combining the neighborhoods that have the same Postcode"}, {"metadata": {}, "cell_type": "markdown", "source": "In reality, one district of Paris has various neighbourhood. That's why we need to combine all of neighbourhood of each district of Paris.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Quicky reviewing the information of dataframe\ndf_neighbourhood.info()", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 102 entries, 0 to 101\nData columns (total 2 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   postcode       102 non-null    object\n 1   neighbourhood  102 non-null    object\ndtypes: object(2)\nmemory usage: 1.7+ KB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "### Convert into string all of values in dataframe\ndf_neighbourhood = df_neighbourhood.astype(str)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_neighbourhood.info()", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 102 entries, 0 to 101\nData columns (total 2 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   postcode       102 non-null    object\n 1   neighbourhood  102 non-null    object\ndtypes: object(2)\nmemory usage: 1.7+ KB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "df_neighbourhood.info()", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 102 entries, 0 to 101\nData columns (total 2 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   postcode       102 non-null    object\n 1   neighbourhood  102 non-null    object\ndtypes: object(2)\nmemory usage: 1.7+ KB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "df_neighbourhood.info()", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 102 entries, 0 to 101\nData columns (total 2 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   postcode       102 non-null    object\n 1   neighbourhood  102 non-null    object\ndtypes: object(2)\nmemory usage: 1.7+ KB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "df_combined = df_neighbourhood.groupby(by=[COL_NAME_POSTCODE]).agg(lambda x: \",\".join(x)).reset_index()\ndf_combined", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "   postcode                                    neighbourhood\n0     75001  75002,75003,75004,75005,75006,75007,75008,75009\n1     75002                          75001,75003,75009,75010\n2     75003                    75001,75002,75004,75010,75011\n3     75004              75001,75003,75005,75006,75011,75012\n4     75005              75001,75004,75006,75012,75013,75014\n5     75006              75001,75004,75005,75007,75014,75015\n6     75007                    75001,75006,75008,75015,75016\n7     75008              75001,75007,75009,75016,75017,75018\n8     75009              75001,75002,75008,75010,75017,75018\n9     75010        75002,75003,75009,75011,75018,75019,75020\n10    75011              75003,75004,75010,75012,75019,75020\n11    75012                    75004,75005,75011,75013,75020\n12    75013                                75005,75012,75014\n13    75014                          75005,75006,75013,75015\n14    75015                          75006,75007,75014,75016\n15    75016                          75007,75008,75015,75017\n16    75017                          75008,75009,75016,75018\n17    75018                    75008,75009,75010,75017,75019\n18    75019                          75010,75011,75018,75020\n19    75020                          75010,75011,75012,75019", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postcode</th>\n      <th>neighbourhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75001</td>\n      <td>75002,75003,75004,75005,75006,75007,75008,75009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75002</td>\n      <td>75001,75003,75009,75010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75003</td>\n      <td>75001,75002,75004,75010,75011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75004</td>\n      <td>75001,75003,75005,75006,75011,75012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75005</td>\n      <td>75001,75004,75006,75012,75013,75014</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>75006</td>\n      <td>75001,75004,75005,75007,75014,75015</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>75007</td>\n      <td>75001,75006,75008,75015,75016</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75008</td>\n      <td>75001,75007,75009,75016,75017,75018</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>75009</td>\n      <td>75001,75002,75008,75010,75017,75018</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>75010</td>\n      <td>75002,75003,75009,75011,75018,75019,75020</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>75011</td>\n      <td>75003,75004,75010,75012,75019,75020</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>75012</td>\n      <td>75004,75005,75011,75013,75020</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>75013</td>\n      <td>75005,75012,75014</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>75014</td>\n      <td>75005,75006,75013,75015</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>75015</td>\n      <td>75006,75007,75014,75016</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>75016</td>\n      <td>75007,75008,75015,75017</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>75017</td>\n      <td>75008,75009,75016,75018</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>75018</td>\n      <td>75008,75009,75010,75017,75019</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>75019</td>\n      <td>75010,75011,75018,75020</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>75020</td>\n      <td>75010,75011,75012,75019</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Building the Coordinates of All Districts in Paris\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "if os.path.exists(file_coordinate_path):\n    print(\"Loading file input : {}\".format(file_coordinate_path))\n    df_coordinates = pd.read_csv(file_coordinate_path, header=0)\nelse:\n    # In Paris, France, there are 20 districts\n    list_of_districts_in_Paris = [\"750\" + str(x).zfill(2) for x in range(1, 21)]\n    \n    # Create DataFrame with given list of districts of Paris\n    df_coordinates = pd.DataFrame(data=list_of_districts_in_Paris, columns=[COL_NAME_POSTCODE])\n\n    df_coordinates[COL_NAME_COUNTRY] = \"FR\"\n    df_coordinates[COL_NAME_ADDRESS] = df_coordinates.apply(lambda row: str(row[COL_NAME_POSTCODE]) + \", \" + row[COL_NAME_COUNTRY], axis=1)\n\n    locator = Nominatim(user_agent=\"paris_explorer\")\n\n    # convenient function to delay between geocoding calls\n    geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n\n    # create column \"location\"\n    df_coordinates[COL_NAME_LOCATION] = df_coordinates[COL_NAME_ADDRESS].apply(geocode)\n\n    # extract from location column to (longitude, latitude, altitude)  (returns tuple)\n    df_coordinates[COL_NAME_POINT] = df_coordinates[COL_NAME_LOCATION].apply(lambda loc: tuple(loc.point) if loc else None)\n\n    # split point column into latitude, longitude and altitude columns\n    df_coordinates[[COL_NAME_LATITUDE, COL_NAME_LONGITUDE, COL_NAME_ALTITUDE]] = pd.DataFrame(df_coordinates[COL_NAME_POINT].tolist(), index=df_coordinates.index)\n    \n    # save to file csv\n    df_coordinates.to_csv(file_coordinate_path, header=True, index=False)", "execution_count": 19, "outputs": [{"output_type": "error", "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: 'var/Geospatial_Coordinates_Paris.csv'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-19-d5c40599f478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# save to file csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_coordinate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'var/Geospatial_Coordinates_Paris.csv'"]}]}, {"metadata": {}, "cell_type": "code", "source": "df_coordinates.info()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Removing the useless columns\ndf_coordinates.drop([COL_NAME_COUNTRY, COL_NAME_POINT, COL_NAME_ALTITUDE, COL_NAME_LOCATION], axis=1, inplace=True)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Converting postcode to string\ndf_coordinates[COL_NAME_POSTCODE] = df_coordinates[COL_NAME_POSTCODE].astype(str)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_coordinates.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's review the coordinate of district 1"}, {"metadata": {}, "cell_type": "code", "source": "df_coordinates[df_coordinates[COL_NAME_POSTCODE]==\"75001\"]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's review the coordinate of district 2"}, {"metadata": {}, "cell_type": "code", "source": "df_coordinates[df_coordinates[COL_NAME_POSTCODE]==\"75002\"]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Merging two dataframes\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "# List of columns in dataframe df_neighbourhood\ndf_combined.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# List of columns in dataframe df_coordinates\ndf_coordinates.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_combined.head(2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_combined.head(2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_merged = pd.merge(df_combined, df_coordinates, \n                     left_on=COL_NAME_POSTCODE, right_on=COL_NAME_POSTCODE,\n                     how=\"inner\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_merged\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's review general information of dataframe\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "df_merged.info()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_merged.describe()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Getting the size of merged dataframe\n"}, {"metadata": {}, "cell_type": "code", "source": "print(\"(row, column) = %s\" % str(df_merged.shape))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Exploring and clustering the neighborhoods in Paris\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Listing distinct districts\n"}, {"metadata": {}, "cell_type": "code", "source": "df_merged[COL_NAME_POSTCODE].unique()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Quickly examine the resulting dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "print(\"(row, column) = %s\" % str(df_merged.shape))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_merged.info()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_merged.head(3)\n", "execution_count": 8, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'df_merged' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-8-5c2dfc904d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'df_merged' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "print('The dataframe has {} district and {} neighborhoods.'.format(\n      df_merged[COL_NAME_POSTCODE].nunique(),\n      df_merged.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Using geopy library to get the latitude and longitude values of Paris\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In order to define an instance of the geocoder, we need to define a user_agent. We will name our agent paris_explorer, as shown below.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Get the coordinate of Paris, France\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\ndef get_latitude_longitude(address=\"\"):\n    if not address:\n        return None, None\n    \n    geolocator = Nominatim(user_agent=\"paris_explorer\")\n    location = geolocator.geocode(address)\n    latitude = location.latitude\n    longitude = location.longitude\n    return (latitude, longitude)\n\ndef get_latitude_longitude_paris_fr():\n    address = 'Paris, FR'\n    return get_latitude_longitude(address)\n\nlatitude, longitude = get_latitude_longitude_paris_fr()\nprint('The geograpical coordinate of Paris, FR are {}, {}.'.format(latitude, longitude))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating a map of Paris with neighborhoods superimposed on top\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "import folium\n\n# create map using latitude and longitude values\nm = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# add markers to map\nfor lat, lng, district, neighborhood in zip(df_merged[COL_NAME_LATITUDE], \n                                            df_merged[COL_NAME_LONGITUDE], \n                                            df_merged[COL_NAME_POSTCODE], \n                                            df_merged[COL_NAME_NEIGHBOURHOOD]):\n    label = 'District:{}, Neighbourhood:{}'.format(district, neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(m)  \n    \nm", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining Foursquare Credentials and Version\u00b6\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Next, we are going to start utilizing the Foursquare API to explore the neighborhoods and segment them.\n"}, {"metadata": {}, "cell_type": "code", "source": "CLIENT_ID = 'XXX'     # Foursquare ID\nCLIENT_SECRET = 'XXX' # Foursquare Secret\nVERSION = '20180604'\nLIMIT = 30\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's explore the first neighborhood in our dataframe\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Get the neighborhood's name.\n"}, {"metadata": {}, "cell_type": "code", "source": "df_merged.loc[0, COL_NAME_NEIGHBOURHOOD]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the neighborhood's latitude and longitude values.\n"}, {"metadata": {}, "cell_type": "code", "source": "neighborhood_latitude = df_merged.loc[0, COL_NAME_LATITUDE]   # neighborhood latitude value\nneighborhood_longitude = df_merged.loc[0, COL_NAME_LONGITUDE] # neighborhood longitude value\n\nneighborhood_name = df_merged.loc[0, COL_NAME_NEIGHBOURHOOD] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Now, let's get the top 100 venues that are in \"75002,75003,75004,75005,75006,75007,75008,75009\" within a radius of 500 meters.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "First, let's create the GET request URL. Name your URL url.\n"}, {"metadata": {}, "cell_type": "code", "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\n\n# create URL\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\n\nurl # display URL", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Send the GET request and examine the resutls\n"}, {"metadata": {}, "cell_type": "code", "source": "import requests # library to handle requests\n\nresults = requests.get(url).json()\nresults", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's borrow the get_category_type function from the Foursquare lab.\n"}, {"metadata": {}, "cell_type": "code", "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now we are ready to clean the json and structure it into a pandas dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\nvenues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "And how many venues were returned by Foursquare?\n"}, {"metadata": {}, "cell_type": "code", "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's create a function to repeat the same process to all the neighborhoods\n"}, {"metadata": {}, "cell_type": "code", "source": "COL_NAME_VENUE = \"Venue\"\nCOL_NAME_CATEGORY = \"Category\"\n\nCOL_NAME_NEIGHBOURHOOD_LATITUDE = COL_NAME_NEIGHBOURHOOD + \" \" + COL_NAME_LATITUDE\nCOL_NAME_NEIGHBOURHOOD_LONGITUDE = COL_NAME_NEIGHBOURHOOD + \" \" + COL_NAME_LONGITUDE\nCOL_NAME_VENUE_LATITUDE = COL_NAME_VENUE + \" \" + COL_NAME_LATITUDE\nCOL_NAME_VENUE_LONGITUDE = COL_NAME_VENUE + \" \" + COL_NAME_LONGITUDE\nCOL_NAME_VENUE_CATEGORY = COL_NAME_VENUE + \" \" + COL_NAME_CATEGORY\n\n\ndef get_near_by_venues(names, latitudes, longitudes, radius=500):    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = [COL_NAME_NEIGHBOURHOOD, \n                             COL_NAME_NEIGHBOURHOOD_LATITUDE,\n                             COL_NAME_NEIGHBOURHOOD_LONGITUDE,\n                             COL_NAME_VENUE,\n                             COL_NAME_VENUE_LATITUDE,\n                             COL_NAME_VENUE_LONGITUDE,\n                             COL_NAME_VENUE_CATEGORY]\n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Getting dataframe that contains all the neighborhoods of Paris\n"}, {"metadata": {}, "cell_type": "code", "source": "venues_neighbourhoods = get_near_by_venues(\n    names=df_merged[COL_NAME_NEIGHBOURHOOD],\n    latitudes=df_merged[COL_NAME_LATITUDE],                           \n    longitudes=df_merged[COL_NAME_LONGITUDE])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's check the size of the resulting dataframe\n"}, {"metadata": {}, "cell_type": "code", "source": "print(\"(row, column) = %s\" % str(venues_neighbourhoods.shape))\nvenues_neighbourhoods.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's check how many venues were returned for each neighborhood\n"}, {"metadata": {}, "cell_type": "code", "source": "venues_neighbourhoods.groupby(COL_NAME_NEIGHBOURHOOD).count()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's find out how many unique categories can be curated from all the returned venues\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "venues_neighbourhoods[COL_NAME_VENUE_CATEGORY].unique()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} uniques categories.'.format(\n    len(venues_neighbourhoods[COL_NAME_VENUE_CATEGORY].unique())))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Analyzing Each Neighborhood District in Paris\n"}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\ndf_onehot = pd.get_dummies(venues_neighbourhoods[[COL_NAME_VENUE_CATEGORY]], \n                                        prefix=\"\", \n                                        prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ndf_onehot[COL_NAME_NEIGHBOURHOOD] = venues_neighbourhoods[COL_NAME_NEIGHBOURHOOD] \n\n# move neighborhood column to the first column\nfixed_columns = [df_onehot.columns[-1]] + list(df_onehot.columns[:-1])\ndf_onehot = df_onehot[fixed_columns]\n\ndf_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "And let's examine the new dataframe size.\n"}, {"metadata": {}, "cell_type": "code", "source": "df_onehot.shape\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"}, {"metadata": {}, "cell_type": "code", "source": "df_grouped = df_onehot.groupby(COL_NAME_NEIGHBOURHOOD).mean().reset_index()\ndf_grouped.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's confirm the new size\n"}, {"metadata": {}, "cell_type": "code", "source": "print(\"(row, column) = %s\" % str(df_grouped.shape))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's print each neighborhood along with the top 5 most common venues\n"}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 5\nCOL_NAME_FREQUENCE = 'freq'\n\nfor hood in df_grouped[COL_NAME_NEIGHBOURHOOD]:\n    print(\"----\"+hood+\"----\")\n    temp = df_grouped[df_grouped[COL_NAME_NEIGHBOURHOOD] == hood].T.reset_index()\n    temp.columns = [COL_NAME_VENUE, COL_NAME_FREQUENCE]\n    temp = temp.iloc[1:]\n    temp[COL_NAME_FREQUENCE] = temp[COL_NAME_FREQUENCE].astype(float)\n    temp = temp.round({COL_NAME_FREQUENCE: 2})\n    print(temp.sort_values(COL_NAME_FREQUENCE, ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's put that into a pandas dataframe\n"}, {"metadata": {}, "cell_type": "markdown", "source": "First, let's write a function to sort the venues in descending order.\n"}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now let's create the new dataframe and display the top 10 venues for each neighborhood.\n"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\n\nnum_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = [COL_NAME_NEIGHBOURHOOD]\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted[COL_NAME_NEIGHBOURHOOD] = df_grouped[COL_NAME_NEIGHBOURHOOD]\n\nfor ind in np.arange(df_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(df_grouped.iloc[ind, :], \n                                                                          num_top_venues)\n\nneighborhoods_venues_sorted.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Result and Analysis "}, {"metadata": {}, "cell_type": "markdown", "source": "## Clustering Neighborhoods of Paris, France\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Run k-means to cluster the neighborhood into 6 clusters.\n"}, {"metadata": {}, "cell_type": "code", "source": "# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n# set number of clusters\nkclusters = 6\n\nclustering_grouped_paris = df_grouped.drop(COL_NAME_NEIGHBOURHOOD, 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(clustering_grouped_paris)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood"}, {"metadata": {}, "cell_type": "code", "source": "COL_NAME_CLUSTER_LABELS = 'Cluster Labels'\n\n# add clustering labels\nneighborhoods_venues_sorted.insert(0, COL_NAME_CLUSTER_LABELS, kmeans.labels_)\n\ndf_merged_paris = df_merged\n\ndf_merged_paris = df_merged_paris.join(neighborhoods_venues_sorted.set_index(COL_NAME_NEIGHBOURHOOD), \n                                                           on=COL_NAME_NEIGHBOURHOOD)\n\ndf_merged_paris.head() # check the last columns!", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Let's visualize the resulting clusters\n"}, {"metadata": {}, "cell_type": "code", "source": "# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# Let's get the geographical coordinates of Paris, France\nlatitude, longitude = get_latitude_longitude_paris_fr()\nprint('The geograpical coordinate of Paris, FR are {}, {}.'.format(latitude, longitude))\n# ------------------------------------------------------------------------------------------------\n\n# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, district, poi, cluster in zip(df_merged_paris[COL_NAME_LATITUDE], \n                                  df_merged_paris[COL_NAME_LONGITUDE],\n                                  df_merged_paris[COL_NAME_POSTCODE],\n                                  df_merged_paris[COL_NAME_NEIGHBOURHOOD], \n                                  df_merged_paris[COL_NAME_CLUSTER_LABELS]):\n    label = 'District:{}, Neighbourhood:{}, Number of Cluster:{}'.format(district, poi, cluster+1)\n    label = folium.Popup(label,\n                         parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Examining Clusters\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Now, we can examine each cluster and determine the discriminating venue categories that distinguish each cluster.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Based on the defining categories, we can then assign a name to each cluster.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 1 "}, {"metadata": {}, "cell_type": "code", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 0, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 2"}, {"metadata": {}, "cell_type": "markdown", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 1, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]"}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 3"}, {"metadata": {}, "cell_type": "code", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 2, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 4"}, {"metadata": {}, "cell_type": "code", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 3, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 5"}, {"metadata": {}, "cell_type": "code", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 4, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Cluster 6"}, {"metadata": {}, "cell_type": "code", "source": "df_merged_paris.loc[df_merged_paris[COL_NAME_CLUSTER_LABELS] == 5, \n                    df_merged_paris.columns[[1] + list(range(5, df_merged_paris.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conclusion and Perspective\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Conclusion\n"}, {"metadata": {}, "cell_type": "code", "source": "In above result, we have the clustering result of the various districts based on top 10 venues for each neighborhood.\nThus, as you see, the French Restaurant is the first most common venue in most of districts in Paris.\nWhen reviewing the clusters, we could see that the Vietnamese restaurant in cluster 5. Indeed, as you see, Vietnamese Restaurant is the second and the 10th most common venus in District 13 and District 2, respectively.\nSo, depending on the several requirements of the investors, if we would like to open new Vietnamese restaurant in the district that have already had many Vietnamese restaurant, we should open in District 13.\nOr, we should open new one in District 2, Paris, because this district is also good community for opening Vietnamese restaurant.\nMoreover, if the investor would like to open new one in the districts that are similar to District 13, we could locate it in the districts that are clustered in Cluster 5 such as District 3, 4, 16 in Paris.", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Perspectives"}, {"metadata": {}, "cell_type": "code", "source": "Concerning to enhance the features of district, we should add more relevant features for each district such as:\nthe transport info (public transport, parking, etc.),\nthe information of asian communities,\nthe information of major tourist venues\netc.\nConcerning to clustering methods and enhancing the performances, we could do some experiments with other algorithms, for instance,\nFuzzy c-means method\nDBSCAN: Density-based clustering\nHierarchical K-Means Clustering\nHCPC: Hierarchical clustering on principal components\nDeep Learning Models. To see more detail, please see in \"A Survey of Clustering With Deep Learning: Fromthe Perspective of Network Architecture\" (2018) - https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412085", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## References"}, {"metadata": {}, "cell_type": "code", "source": "The tutorials in course \"Applied Data Science Capstone\" (https://www.coursera.org/learn/applied-data-science-capstone/)\nParis Arrondissements & Neighborhoods Map (https://parismap360.com/paris-arrondissement-map#.XfVpqtEo91l)\nArrondissements in Paris, France (https://francetravelplanner.com/go/paris/areas/arrondismt.html)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}